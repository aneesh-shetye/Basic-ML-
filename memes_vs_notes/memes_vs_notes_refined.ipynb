{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "memes_vs_notes_refined.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1qNbHUhmDWF529qBnoMhAaCjg3LldobfS",
      "authorship_tag": "ABX9TyODsQNtSDlIv5gmT+09DkZk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonOfADev/memes_vs_notes/blob/master/memes_vs_notes_refined.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfHMe1nhdg4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import os\n",
        " \n",
        "folder = \"/content/drive/My Drive/Memes_vs_Notes/\"\n",
        "classes = [\"Memes\", \"Notes\"]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTI4FryLeBCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "def load_data(folder, classes, IMG_HEIGHT, IMG_WIDTH):\n",
        "    data = []\n",
        "    data_dnn = []\n",
        "    labels = []\n",
        "    label = -1\n",
        "    for y in classes:\n",
        "        label += 1\n",
        "        path = folder + str(y)+\"/\"\n",
        "        for x in os.listdir(path):\n",
        "            img = cv2.imread(path + str(x))\n",
        "            img = cv2.resize(img,(IMG_WIDTH, IMG_HEIGHT))\n",
        "            data.append(img)       \n",
        "            labels.append(label)\n",
        "    dataset = np.array([np.array(x) for x in data])\n",
        "    dataset, labels = shuffle (dataset, labels, random_state=0) \n",
        "    dataset = torch.Tensor(dataset)\n",
        "    labels = torch.Tensor(labels)  \n",
        "     \n",
        "    return dataset, labels"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXnaiiQI4Uwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_HEIGHT = 100\n",
        "IMG_WIDTH git remote add origin https://github.com/SonOfADev/memes_vs_notes.git= 100\n",
        "data, labels = load_data(folder, classes, IMG_HEIGHT, IMG_WIDTH)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI1JMToHoa1H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "220eaf15-3587-4b5e-8118-7951ee62f6a3"
      },
      "source": [
        "device =  torch.device(\"cpu\")\n",
        "data = data/255\n",
        "\n",
        "data.shape, labels.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1600, 100, 100, 3]), torch.Size([1600]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7DqAEPepurO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # self.layer5 = nn.Sequential(\n",
        "        #     nn.Conv2d(256, 512, kernel_size=5, stride=1, padding=2),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # self.layer6 = nn.Sequential(\n",
        "        #     nn.Conv2d(512, 258, kernel_size=1, stride=1),\n",
        "        #     nn.ReLU()\n",
        "        # )\n",
        "        #self.drop_out = nn.Dropout()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(6 *6 * 256,1000),\n",
        "            nn.ReLU())\n",
        "        self.fc2 = nn.Linear(1000, 1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        # out = self.layer5(out)\n",
        "        # out = self.layer6(out)\n",
        "        out = out.reshape(out.size(0),-1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZCA3NlSrw-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ConvNet()\n",
        "model.to(device)\n",
        "learning_rate = 0.001\n",
        "# Loss and optimizer\n",
        "criterion =torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2YD8cRTugN9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "239e0b10-ee73-4311-b460-8f86ea9b79fe"
      },
      "source": [
        "data_resized = data.reshape(-1,3,100,100)\n",
        "#data_resized = torch.Tensor(data_resized)\n",
        "train_data = data_resized[:1000]\n",
        "train_labels = labels[:1000]\n",
        "valid_data = data_resized[1000:1300]\n",
        "valid_labels = labels[1000:1300]\n",
        "test_data = data_resized[1300:1600]\n",
        "test_labels = labels[1300:1600]\n",
        "np.shape(train_data)\n",
        "\n",
        "train_data = train_data.to(device)\n",
        "train_labels = train_labels.to(device)\n",
        "\n",
        "valid_data = valid_data.to(device)\n",
        "valid_lables = valid_labels.to(device)\n",
        "\n",
        "test_data = test_data.to(device)\n",
        "test_labels = test_labels.to(device)\n",
        "train_data.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 3, 100, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2VAzSxuRIKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8d7400d-0de7-41cf-d9f6-d05199baa743"
      },
      "source": [
        "#train_labels = train_labels.type(torch.LongTensor) \n",
        "train_labels = train_labels.unsqueeze(-1)\n",
        "valid_labels = valid_labels.unsqueeze(-1)\n",
        "test_labels = test_labels.unsqueeze(-1)\n",
        "train_labels.type(), train_labels.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('torch.FloatTensor', torch.Size([1000, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klC2vTRxu89H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "e50f454d-36fa-4ebd-dd98-796248d3841b"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "num_epochs = 10\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    outputs = model(train_data)\n",
        "    loss = criterion(outputs, train_labels)\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "    # Backprop and perform Adam optimisation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Track the accuracy\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        #outputs = net(images)\n",
        "        outputs_valid = model(valid_data)\n",
        "        valid_loss = criterion(outputs_valid, valid_labels)\n",
        "\n",
        "        predicted_valid = (torch.sigmoid(outputs_valid.data)>0.5)\n",
        "\n",
        "        predicted = (F.sigmoid(outputs.data)>0.5)\n",
        "\n",
        "        total = train_labels.size(0)\n",
        "        correct = (predicted == train_labels).sum().item()\n",
        "\n",
        "        total_valid = valid_labels.size(0)\n",
        "        correct_valid = (predicted_valid == valid_labels).sum().item()\n",
        "\n",
        "    print(\"training accuracy %d %%\" %(100*correct/total ))\n",
        "    print('validation Accuracy: %d %%' % (100 * correct_valid / total_valid))\n",
        "    print(f\"train loss = {loss}\")\n",
        "    print(f\"validation loss = {valid_loss}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training accuracy 90 %\n",
            "validation Accuracy: 92 %\n",
            "train loss = 0.2628377377986908\n",
            "validation loss = 0.258310467004776\n",
            "training accuracy 93 %\n",
            "validation Accuracy: 92 %\n",
            "train loss = 0.18582525849342346\n",
            "validation loss = 0.2797485589981079\n",
            "training accuracy 93 %\n",
            "validation Accuracy: 92 %\n",
            "train loss = 0.20515060424804688\n",
            "validation loss = 0.26262524724006653\n",
            "training accuracy 93 %\n",
            "validation Accuracy: 93 %\n",
            "train loss = 0.18584175407886505\n",
            "validation loss = 0.2434297502040863\n",
            "training accuracy 95 %\n",
            "validation Accuracy: 92 %\n",
            "train loss = 0.14151953160762787\n",
            "validation loss = 0.27091842889785767\n",
            "training accuracy 94 %\n",
            "validation Accuracy: 92 %\n",
            "train loss = 0.16468903422355652\n",
            "validation loss = 0.25354695320129395\n",
            "training accuracy 95 %\n",
            "validation Accuracy: 94 %\n",
            "train loss = 0.14452633261680603\n",
            "validation loss = 0.20631812512874603\n",
            "training accuracy 96 %\n",
            "validation Accuracy: 95 %\n",
            "train loss = 0.1184215173125267\n",
            "validation loss = 0.21137364208698273\n",
            "training accuracy 95 %\n",
            "validation Accuracy: 95 %\n",
            "train loss = 0.14082205295562744\n",
            "validation loss = 0.19183970987796783\n",
            "training accuracy 96 %\n",
            "validation Accuracy: 94 %\n",
            "train loss = 0.12241317331790924\n",
            "validation loss = 0.18607459962368011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfIZnCHZFL0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_STORE_PATH = \"/content/drive/\"\n",
        "torch.save(model.state_dict(), MODEL_STORE_PATH + 'conv_net_model.ckpt')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}