{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "memes_vs_notes_dnn_numpy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SwRKykATUyX--1HOmXGa1jfJDEe9K8N9",
      "authorship_tag": "ABX9TyMO3x+CM5uJei4VgIs0A9Yr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonOfADev/memes_vs_notes/blob/master/dnn_numpy_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyFUGpS879ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yA_89nX8Ka0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialization(next_layer_dims, prev_layer_dims):\n",
        "    # random initialization because kaiming initialization was giving a problem \n",
        "    W  = np.random.randn(next_layer_dims, prev_layer_dims)*0.01\n",
        "    b = np.zeros([next_layer_dims,1])\n",
        "    return W, b"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNsGCv-28OuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_prop(A_prev, W, b):\n",
        "    Z = np.dot(W, A_prev)+b\n",
        "    \n",
        "    return Z"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLM3aVf48Q3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activation_function(Z, activation):\n",
        "    if activation == 'sigmoid':\n",
        "        A = 1/(1+np.exp(-Z))\n",
        "\n",
        "    if activation == 'relu':\n",
        "        A = np.maximum(Z, 0)\n",
        "\n",
        "    return A "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTQ4y6jC8TEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost_function(AL, label):\n",
        "\n",
        "    m = AL.shape[1]\n",
        "    #epsilon = 0.00000001\n",
        "    cost = -1/m*(np.sum(label*np.log(AL)+(1-label)*np.log(1-AL)))\n",
        "    assert cost.shape == ()\n",
        "\n",
        "    return cost"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYGSRSqq8VlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu_grad(dA, A):\n",
        "    dZ = np.array(dA, copy=True)\n",
        "   \n",
        "    dZ[A == 0] = 0\n",
        "    return dZ"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh2rhnkI8Y8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid_grad(A, Y):\n",
        "    return A-Y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6EGHY4w8bXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backward_prop(dZ, A_prev, W ):\n",
        "\n",
        "    m = A_prev.shape[1]\n",
        "    dW = 1/m*(np.dot(dZ, A_prev.T))\n",
        "    db = 1/m*np.sum(dZ, axis=1, keepdims=True)\n",
        "    dA_prev = np.dot(W.T, dZ)\n",
        "\n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dxLwkMcridv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVxt8Voi8eMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_model(no_of_layers, nL, X, y, learning_rate, EPOCHS, val_x, val_y, batches):\n",
        "\n",
        "    param= {}\n",
        "    \n",
        "    \n",
        "    Z = {}\n",
        "    #initializing parameters:\n",
        "    for l in range(1, no_of_layers):\n",
        "        param[\"W\" + str(l)], param[\"b\" + str(l)] = initialization(nL[l],nL[l-1])   \n",
        "        W = param[\"W\" + str(l)]\n",
        "        x = W.shape\n",
        "\n",
        "    for epochs in range(EPOCHS):\n",
        "        correct = 0\n",
        "        total_loss = 0\n",
        "        batch_size = X.shape[1]//batches\n",
        "        for b in range(batches):\n",
        "            Y = y[b*batch_size:(b+1)*batch_size]\n",
        "            results={\"A0\":X[:,b*batch_size:(b+1)*batch_size]}\n",
        "            for l in range(1, no_of_layers-1):\n",
        "                \n",
        "                #initialization of parameters \n",
        "                W = param[\"W\" + str(l)]\n",
        "                b = param[\"b\" + str(l)]\n",
        "\n",
        "                #forward propogation \n",
        "                Z[\"Z\"+ str(l)] = forward_prop(results[\"A\" + str(l-1)], W, b)\n",
        "                results[\"A\"+ str(l)] = activation_function( Z[\"Z\"+str(l)], activation=\"relu\")\n",
        "                ##################################\n",
        "\n",
        "            Z[\"Z\" + str(no_of_layers-1)] = forward_prop(results[\"A\" + str(no_of_layers-2 )], param[\"W\"+str(no_of_layers-1)], param[\"b\"+str(no_of_layers-1)])\n",
        "\n",
        "            results[\"A\"+ str(no_of_layers-1)] = activation_function( Z[\"Z\"+ str(no_of_layers-1)], activation=\"sigmoid\") \n",
        "             ##############################\n",
        "            \n",
        "            #finding cost:\n",
        "\n",
        "            cost = cost_function(results[\"A\"+ str(no_of_layers-1)], Y)\n",
        "\n",
        "        \n",
        "            #backward prop :\n",
        "            grads = {}\n",
        "\n",
        "            AL = results[\"A\"+ str(no_of_layers-1)] \n",
        "            #print(AL.shape)\n",
        "            grads[\"dA\"+str(no_of_layers-1)] = -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "            dZ = grads[\"dA\"+str(no_of_layers-1)]*sigmoid_grad(AL, Z[\"Z\" + str(no_of_layers-1)])\n",
        "\n",
        "\n",
        "            ###################\n",
        "            for l in range(no_of_layers-1,0,-1):\n",
        "                grads[\"dA\"+str(l-1)],  grads[\"dW\"+str(l)], grads[\"db\"+str(l)] = backward_prop(dZ, results[\"A\"+str(l-1)], param[\"W\"+str(l)] )\n",
        "                dZ = relu_grad(grads[\"dA\"+str(l-1)],results[\"A\"+str(l-1)])\n",
        "\n",
        "\n",
        "            # updating the parameters:\n",
        "\n",
        "            for l in range(1,no_of_layers):\n",
        "                param[\"W\"+str(l)] = param[\"W\"+str(l)] - learning_rate*grads[\"dW\"+str(l)]\n",
        "                param[\"b\"+str(l)] = param[\"b\"+str(l)] - learning_rate*grads[\"db\"+str(l)] \n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "            total_loss += cost_function(results[\"A\"+ str(no_of_layers-1)], Y)\n",
        "\n",
        "            AL = AL.reshape(-1)\n",
        "            predictions =np.array([AL>0.5])\n",
        "            correct += (predictions == Y).sum().item()\n",
        "\n",
        "        print(f\"EPOCH: {epochs+1}\")\n",
        "        print(f\"accuracy_train:{0.1*correct}\")\n",
        "        print(\"\")\n",
        "        print(f\"train_cost={total_loss/batches}\")\n",
        "        print(\"\")\n",
        "        validation(no_of_layers, nL, val_x, val_y, param)\n",
        "        print(\"\")\n",
        "\n",
        "    return param\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFP-VC2Yl_oW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation(no_of_layers, nL, X, Y, param):\n",
        "\n",
        "    results={\"A0\":X}   \n",
        "    Z = {}\n",
        "    for l in range(1, no_of_layers-1):\n",
        "            #initialization of parameters \n",
        "            W = param[\"W\" + str(l)]\n",
        "            b = param[\"b\" + str(l)]\n",
        "\n",
        "            #forward propogation \n",
        "            Z[\"Z\"+ str(l)] = forward_prop(results[\"A\" + str(l-1)], W, b)\n",
        "            results[\"A\"+ str(l)] = activation_function( Z[\"Z\"+str(l)], activation=\"relu\")\n",
        "            ##################################\n",
        "\n",
        "    Z[\"Z\" + str(no_of_layers-1)] = forward_prop(results[\"A\" + str(no_of_layers-2 )], param[\"W\"+str(no_of_layers-1)], param[\"b\"+str(no_of_layers-1)])\n",
        "    results[\"A\"+ str(no_of_layers-1)] = activation_function( Z[\"Z\"+ str(no_of_layers-1)], activation=\"sigmoid\")\n",
        " \n",
        " ##############################\n",
        "    \n",
        "    #finding cost:\n",
        "    AL = results[\"A\"+ str(no_of_layers-1)]\n",
        "\n",
        "    cost = cost_function(results[\"A\"+ str(no_of_layers-1)], Y)\n",
        "\n",
        "    print(f\"cost_valid ={cost}\")\n",
        "\n",
        "    \n",
        "\n",
        "    predictions = [AL>0.5]\n",
        "    total = Y.shape[0]\n",
        "    correct = (predictions == Y).sum().item()\n",
        "    print(f\"acc_valid:{100*correct/total}\")\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baZwj1R29OOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import PIL \n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        " \n",
        "folder = \"/content/drive/My Drive/Memes_vs_Notes/\"\n",
        "classes = [\"Memes\", \"Notes\"]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7XROtit9Z3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "def load_data(folder, classes, IMG_HEIGHT, IMG_WIDTH):\n",
        "    data = []\n",
        "    labels = []\n",
        "    label = -1\n",
        "    for y in classes:\n",
        "        label += 1\n",
        "        path = folder + str(y)+\"/\"\n",
        "        for x in os.listdir(path):\n",
        "            img = cv2.imread((path + str(x)),0)\n",
        "            img = cv2.resize(img,(IMG_WIDTH, IMG_HEIGHT))\n",
        "            data.append(img)      \n",
        "            labels.append(label)\n",
        "\n",
        "    data, labels = shuffle(data, labels,random_state=0)\n",
        "    # return train_data, train_labels, valid_data, valid_labels, test_data, test_labels\n",
        "    return data, labels"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gdrfr6p_mTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_HEIGHT = 50\n",
        "IMG_WIDTH = 50\n",
        "\n",
        "# train_data, train_labels, valid_data, valid_labels, test_data, test_labels = load_data(folder, classes, IMG_HEIGHT, IMG_WIDTH)\n",
        "data, labels = load_data(folder, classes, IMG_HEIGHT, IMG_WIDTH)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9ylTSox_roh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_data = data[:1000]\n",
        "train_labels = labels[:1000]\n",
        "valid_data = data[1000:1300]\n",
        "valid_labels = labels[1000:1300]\n",
        "test_data = data[1300:1600]\n",
        "test_labels = labels[1300:1600]\n",
        "np.shape(train_data)\n",
        "\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "valid_labels = np.array(valid_labels)\n",
        "\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "\n",
        "data = np.array(data, dtype=\"float\")\n",
        "labels = np.array(labels)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ml5FwQBOlNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = np.array(train_data)\n",
        "\n",
        "valid_data = np.array(valid_data)\n",
        "\n",
        "test_data = np.array(test_data)\n",
        "\n",
        "train_data = (train_data.reshape(train_data.shape[0],-1)).T\n",
        "\n",
        "valid_data = valid_data.reshape(valid_data.shape[0], -1).T\n",
        "\n",
        "test_data = test_data.reshape(test_data.shape[0],-1).T"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9_SNgUhu6tA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3556a56-2401-49eb-f852-f586e3ec9f76"
      },
      "source": [
        "\n",
        "total_train = np.sum([x==1 for x in train_labels])\n",
        "total_valid = np.sum([x==1 for x in valid_labels])\n",
        "total_test = np.sum([x==1 for x in test_labels])\n",
        "total_train, total_valid, total_test  # to check for bias in train data this was even done for valid_data and test_datra"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(494, 158, 148)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApfDAdZXFhwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data/255.0\n",
        "valid_data = valid_data/255.0"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4EFBrwTujXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26c8cc2e-45aa-4e34-a7c9-d8879d3b83d2"
      },
      "source": [
        "\n",
        "type(train_data[0,0]), train_labels.shape, train_data.shape, valid_data.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.float64, (1000,), (2500, 1000), (2500, 300))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgA72KTsPRJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30ae6aa2-0453-418b-b36e-b99730d5c79f"
      },
      "source": [
        "nL = [train_data.shape[0],320, 128,1 ] \n",
        "params = training_model(4, nL, train_data, train_labels, 0.001, 25, valid_data, valid_labels, 50)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 1\n",
            "accuracy_train:50.300000000000004\n",
            "\n",
            "train_cost=0.6930225580581246\n",
            "\n",
            "cost_valid =0.6930296138786021\n",
            "acc_valid:47.333333333333336\n",
            "\n",
            "EPOCH: 2\n",
            "accuracy_train:54.6\n",
            "\n",
            "train_cost=0.6929016433720276\n",
            "\n",
            "cost_valid =0.6929149052502787\n",
            "acc_valid:51.333333333333336\n",
            "\n",
            "EPOCH: 3\n",
            "accuracy_train:61.6\n",
            "\n",
            "train_cost=0.6927875638153583\n",
            "\n",
            "cost_valid =0.6928042832177438\n",
            "acc_valid:58.666666666666664\n",
            "\n",
            "EPOCH: 4\n",
            "accuracy_train:70.60000000000001\n",
            "\n",
            "train_cost=0.6926769075398868\n",
            "\n",
            "cost_valid =0.6926947216483705\n",
            "acc_valid:67.33333333333333\n",
            "\n",
            "EPOCH: 5\n",
            "accuracy_train:74.7\n",
            "\n",
            "train_cost=0.6925635092176949\n",
            "\n",
            "cost_valid =0.6925842808967102\n",
            "acc_valid:72.0\n",
            "\n",
            "EPOCH: 6\n",
            "accuracy_train:75.8\n",
            "\n",
            "train_cost=0.6924488388484413\n",
            "\n",
            "cost_valid =0.692478588764091\n",
            "acc_valid:74.0\n",
            "\n",
            "EPOCH: 7\n",
            "accuracy_train:77.30000000000001\n",
            "\n",
            "train_cost=0.6923362832829731\n",
            "\n",
            "cost_valid =0.6923746478937592\n",
            "acc_valid:75.66666666666667\n",
            "\n",
            "EPOCH: 8\n",
            "accuracy_train:77.9\n",
            "\n",
            "train_cost=0.6922230139683283\n",
            "\n",
            "cost_valid =0.6922682889959533\n",
            "acc_valid:77.0\n",
            "\n",
            "EPOCH: 9\n",
            "accuracy_train:78.4\n",
            "\n",
            "train_cost=0.6921065793652417\n",
            "\n",
            "cost_valid =0.692159077598169\n",
            "acc_valid:77.0\n",
            "\n",
            "EPOCH: 10\n",
            "accuracy_train:78.9\n",
            "\n",
            "train_cost=0.6919871645748252\n",
            "\n",
            "cost_valid =0.6920469093888254\n",
            "acc_valid:77.0\n",
            "\n",
            "EPOCH: 11\n",
            "accuracy_train:79.10000000000001\n",
            "\n",
            "train_cost=0.6918641035880523\n",
            "\n",
            "cost_valid =0.691930670597995\n",
            "acc_valid:76.33333333333333\n",
            "\n",
            "EPOCH: 12\n",
            "accuracy_train:79.0\n",
            "\n",
            "train_cost=0.6917352480550127\n",
            "\n",
            "cost_valid =0.6918091328822094\n",
            "acc_valid:76.66666666666667\n",
            "\n",
            "EPOCH: 13\n",
            "accuracy_train:78.7\n",
            "\n",
            "train_cost=0.6915995037427962\n",
            "\n",
            "cost_valid =0.6916827455611402\n",
            "acc_valid:77.33333333333333\n",
            "\n",
            "EPOCH: 14\n",
            "accuracy_train:78.9\n",
            "\n",
            "train_cost=0.6914597905594775\n",
            "\n",
            "cost_valid =0.6915528664611446\n",
            "acc_valid:76.66666666666667\n",
            "\n",
            "EPOCH: 15\n",
            "accuracy_train:79.0\n",
            "\n",
            "train_cost=0.6913167158330331\n",
            "\n",
            "cost_valid =0.691416781938423\n",
            "acc_valid:77.66666666666667\n",
            "\n",
            "EPOCH: 16\n",
            "accuracy_train:79.4\n",
            "\n",
            "train_cost=0.6911666031378759\n",
            "\n",
            "cost_valid =0.691272616282357\n",
            "acc_valid:78.33333333333333\n",
            "\n",
            "EPOCH: 17\n",
            "accuracy_train:80.10000000000001\n",
            "\n",
            "train_cost=0.6910079887712405\n",
            "\n",
            "cost_valid =0.6911181040959219\n",
            "acc_valid:78.33333333333333\n",
            "\n",
            "EPOCH: 18\n",
            "accuracy_train:80.4\n",
            "\n",
            "train_cost=0.6908389571409717\n",
            "\n",
            "cost_valid =0.6909511771416089\n",
            "acc_valid:78.66666666666667\n",
            "\n",
            "EPOCH: 19\n",
            "accuracy_train:81.7\n",
            "\n",
            "train_cost=0.6906581399120629\n",
            "\n",
            "cost_valid =0.6907721320622223\n",
            "acc_valid:78.33333333333333\n",
            "\n",
            "EPOCH: 20\n",
            "accuracy_train:82.7\n",
            "\n",
            "train_cost=0.6904648388460686\n",
            "\n",
            "cost_valid =0.6905803735488641\n",
            "acc_valid:78.66666666666667\n",
            "\n",
            "EPOCH: 21\n",
            "accuracy_train:83.80000000000001\n",
            "\n",
            "train_cost=0.6902580868878857\n",
            "\n",
            "cost_valid =0.6903744887343232\n",
            "acc_valid:80.33333333333333\n",
            "\n",
            "EPOCH: 22\n",
            "accuracy_train:84.0\n",
            "\n",
            "train_cost=0.6900364203274394\n",
            "\n",
            "cost_valid =0.690152852193836\n",
            "acc_valid:81.66666666666667\n",
            "\n",
            "EPOCH: 23\n",
            "accuracy_train:85.5\n",
            "\n",
            "train_cost=0.6897979612425185\n",
            "\n",
            "cost_valid =0.6899135459627561\n",
            "acc_valid:82.66666666666667\n",
            "\n",
            "EPOCH: 24\n",
            "accuracy_train:87.10000000000001\n",
            "\n",
            "train_cost=0.6895416948605413\n",
            "\n",
            "cost_valid =0.6896566123058424\n",
            "acc_valid:82.66666666666667\n",
            "\n",
            "EPOCH: 25\n",
            "accuracy_train:88.30000000000001\n",
            "\n",
            "train_cost=0.6892663026151656\n",
            "\n",
            "cost_valid =0.6893797162089872\n",
            "acc_valid:84.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt2vAW794CVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}